#include "llava_impl.hpp"
#include "llava_weight.hpp"

#include "../../tensor.hpp"
#include "../../utils.hpp"
#include "../inference_context.hpp"
#include "infinicore_infer/models/llava.h"

#include <random>
#include <thread>
#include <vector>
#include <fstream>
#include <iomanip>

// LLaVAè®¾å¤‡èµ„æºåˆ›å»ºå‡½æ•°ï¼Œæ¨¡ä»¿jiuge.cppçš„createDeviceResource
void createLlavaDeviceResource(LlavaDeviceResource *rsrc, const LlavaMeta *meta,
                             const LlavaWeights *weights,
                             infiniDevice_t device, int idev, int ndev, int dev_id,
                             infinicclComm_t comm) {
    RUN_INFINI(infinirtSetDevice(device, dev_id));
    infiniopHandle_t handle;
    infiniopCreateHandle(&handle);
    infinirtStream_t stream;
    infinirtStreamCreate(&stream);

    // åˆå§‹åŒ–memory_pool
    auto memory_pool = std::make_shared<MemoryPool>(128 * 1024 * 1024);

    // åˆå§‹åŒ–Language Modelæƒé‡ï¼ˆæš‚æ—¶ä¸ºç©ºï¼Œå¤ç”¨jiugeç»“æ„ï¼‰
    std::vector<std::shared_ptr<Tensor>> w_attn_norm, w_attn_qkv, b_attn_qkv, w_attn_q_norm, w_attn_k_norm, w_attn_out,
        w_ffn_norm, w_ffn_gate_up, w_ffn_down;

    // åˆå§‹åŒ–Vision Encoderæƒé‡
    auto vision_patch_embed_weight = getPatchEmbedWeight(meta, weights);
    auto vision_position_embedding = createPositionEmbedding(meta, weights); // ä»metaä¸­è·å–å½¢çŠ¶
    auto vision_class_token = getClassToken(meta, weights); // ä»metaä¸­è·å–å½¢çŠ¶
    // auto vision_class_embedding = getClassToken(meta);

    // ä¸´æ—¶åˆ›å»ºlanguage modelæƒé‡ï¼ˆå°†æ¥åº”è¯¥ä»weightsä¸­åŠ è½½ï¼‰
    std::shared_ptr<Tensor> w_in_embd = nullptr;
    std::shared_ptr<Tensor> w_out_norm = nullptr;
    std::shared_ptr<Tensor> w_out_embd = nullptr;
    std::shared_ptr<Tensor> sin_table = nullptr;
    std::shared_ptr<Tensor> cos_table = nullptr;

    *rsrc = LlavaDeviceResource{
        device,
        dev_id,
        handle,
        w_in_embd, w_out_norm, w_out_embd, sin_table, cos_table,
        w_attn_norm, w_attn_qkv, b_attn_qkv, w_attn_q_norm, w_attn_k_norm, w_attn_out,
        w_ffn_norm, w_ffn_gate_up, w_ffn_down,
        vision_patch_embed_weight,
        vision_position_embedding, // TODO: ä¸çŸ¥é“æ˜¯ä»€ä¹ˆä½†å…ˆæ”¾è¿™å„¿
        vision_class_token, // TODO: ä¸çŸ¥é“æ˜¯ä»€ä¹ˆä½†å…ˆæ”¾è¿™å„¿
        stream,
        comm,
        memory_pool,
    };
    RUN_INFINI(infinirtDeviceSynchronize());
}

void releaseDeviceResource(LlavaDeviceResource &res) {
    infinirtDeviceSynchronize();
    // Release individual Tensors
    res.w_in_embd.reset();
    res.w_out_norm.reset();
    res.w_out_embd.reset();
    res.sin_table.reset();
    res.cos_table.reset();
    for (auto &t : res.w_attn_norm) {
        t.reset();
    }
    res.w_attn_norm.clear();
    for (auto &t : res.w_attn_qkv) {
        t.reset();
    }
    res.w_attn_qkv.clear();
    for (auto &t : res.b_attn_qkv) {
        t.reset();
    }
    res.b_attn_qkv.clear();
    for (auto &t : res.w_attn_out) {
        t.reset();
    }
    res.w_attn_out.clear();
    for (auto &t : res.w_ffn_norm) {
        t.reset();
    }
    res.w_ffn_norm.clear();
    for (auto &t : res.w_ffn_gate_up) {
        t.reset();
    }
    res.w_ffn_gate_up.clear();
    for (auto &t : res.w_ffn_down) {
        t.reset();
    }
    res.w_ffn_down.clear();
    infiniopDestroyHandle(res.handle);
    res.handle = nullptr;
    infinirtStreamDestroy(res.stream);
    res.stream = nullptr;
    infinicclCommDestroy(res.comm);
    res.comm = nullptr;
}


// LLaVAè§†è§‰ç¼–ç è®¾å¤‡å±‚æ¨ç†å‡½æ•°ï¼ˆæ¨¡ä»¿inferDeviceBatchï¼‰
void inferDeviceBatchVision(const LlavaMeta &meta, LlavaDeviceResource &rsrc,
                           uint32_t idev, uint32_t ndev,
                           const void *image_data, uint32_t *output) {

// inputs["input_ids"].shape: torch.Size([1, 593])
// shape of weight: torch.Size([1024, 3, 14, 14])
// shape of input: torch.Size([1, 3, 336, 336])
// shape of output: torch.Size([1, 1024, 24, 24])
// Debug: print image_data pointer

    // === 1. å‡†å¤‡å‚æ•° ===
    auto vision_embed_dim = meta.vision_meta.vision_embed_dim; // 1024
    auto image_size = meta.vision_meta.image_size; // 336
    auto patch_size = meta.vision_meta.patch_size; // 14
    auto dt_logits = meta.language_meta.dt_logits; // F16
    auto stream = rsrc.stream;

    // è®¡ç®—patchesæ•°é‡
    auto patches_per_dim = image_size / patch_size; // 24
    // auto total_patches = patches_per_dim * patches_per_dim;

    // === 2. å‡†å¤‡buffer ===
    // auto input_image_tensor_f32 = Tensor::buffer(INFINI_DTYPE_F32, {1, 3, image_size, image_size}, rsrc.memory_pool);
    auto input_image_tensor = Tensor::buffer(dt_logits, {1, 3, image_size, image_size}, rsrc.memory_pool);
    auto patch_embed_output = Tensor::buffer(dt_logits, {1, vision_embed_dim, patches_per_dim, patches_per_dim}, rsrc.memory_pool);

    // å¤åˆ¶è¾“å…¥å›¾åƒæ•°æ®
    RUN_INFINI(infinirtMemcpyAsync(input_image_tensor->data(), image_data,
                                  image_size * image_size * 3 * sizeof(uint16_t),
                                  INFINIRT_MEMCPY_H2D, stream));

    // printf("DEBUG: input_image_tensor after memcpy:\n");
    // input_image_tensor->debug_first_n(10);

    // === 3. CLIPVisionEmbeddings Forward ===
    // Step 1: Patch Embedding (Conv2d)

    printf("DEBUG: Running Conv2d: input [1,3,%ld,%ld] -> output [1,%ld,%ld,%ld]\n",
           image_size, image_size, vision_embed_dim, patches_per_dim, patches_per_dim);

    // å‡†å¤‡å·ç§¯å‚æ•°
    std::vector<size_t> pads = {0, 0};  // æ— padding
    std::vector<size_t> strides = {static_cast<size_t>(patch_size), static_cast<size_t>(patch_size)};
    std::vector<size_t> dilations = {1, 1};

    // patch_embeds = self.patch_embedding(pixel_values.to(dtype=target_dtype))  # Conv2d
    conv2d(patch_embed_output, input_image_tensor, rsrc.vision_patch_embed_weight,
           nullptr, pads, strides, dilations); // ï¼ˆ1ï¼Œ1024ï¼Œ24ï¼Œ24ï¼‰

    // flatten 2D patch -> [batch, embed_dim, total_patches]
    auto total_patches = patches_per_dim * patches_per_dim;
    auto patch_embed_flat = patch_embed_output->view({1, vision_embed_dim, total_patches});

    // transpose -> [batch, total_patches, embed_dim]
    auto patch_embed_transposed = patch_embed_flat->permute({0, 2, 1});
    // åˆ›å»º class embedding buffer
    // class_embeds = self.class_embedding.expand(batch_size, 1, -1)
    // assume batch=1

    auto class_embed_tensor = Tensor::buffer(dt_logits, {1, 1, vision_embed_dim}, rsrc.memory_pool); 
    // Tensor: shape[ 1 1 1024 ]
    RUN_INFINI(infinirtMemcpyAsync(class_embed_tensor->data(),
                                rsrc.vision_class_token->data(),
                                sizeof(uint16_t) * vision_embed_dim,
                                INFINIRT_MEMCPY_D2D, stream));


    // embeddings = torch.cat([class_embeds, patch_embeds], dim=1)
    auto embeddings = Tensor::buffer(dt_logits, {1, 1 + total_patches, vision_embed_dim}, rsrc.memory_pool);
    // [ 1 577 1024 ]

    // 1) æŠŠ class token æ”¾åˆ° embeddings[:, 0:1, :]
    rearrange(embeddings->slice(1, 0, 1), class_embed_tensor); // æ³¨æ„ï¼šslice(dim=1, start=0, length=1)

    // 2) æŠŠæ‰€æœ‰ patch token æ”¾åˆ° embeddings[:, 1:1+T, :]
    rearrange(embeddings->slice(1, 1, total_patches), patch_embed_transposed); // æ³¨æ„ï¼šslice(dim=1, start=1, length=total_patches)

    printf("DEBUG: embeddings after concat:\n");
    embeddings->debug_first_n(10);
    rsrc.vision_position_embedding->debug_first_n(10);

    // 3) åŠ  position embedding ï¼ˆpos tensor å¿…é¡»æ˜¯ [1, 1+T, C]ï¼‰
    add(embeddings, embeddings, rsrc.vision_position_embedding);

}




// LLaVAè®¾å¤‡å·¥ä½œçº¿ç¨‹å‡½æ•°ï¼Œä¸¥æ ¼æŒ‰ç…§jiuge.cppçš„launchDeviceç»“æ„
void launchLlavaDevice(const LlavaMeta &meta, const LlavaWeights *weights,
                     LlavaDeviceResource *rsrc, LlavaInferState &state,
                     LlavaRequest &req,
                     infiniDevice_t device, int idev, int ndev, int dev_id,
                     infinicclComm_t comm) {
    // Create Device Resource
    // åˆå§‹åŒ–è®¾å¤‡èµ„æº
    createLlavaDeviceResource(rsrc, &meta, weights, device, idev, ndev, dev_id, comm);

    CacheManager cache_manager(100);
    InferenceContext ctx(rsrc->handle, rsrc->memory_pool, &cache_manager, rsrc->stream);
    setInferenceContext(&ctx);

    // é€šçŸ¥ä¸»çº¿ç¨‹ï¼šè¿™ä¸ªè®¾å¤‡å·²ç»åŠ è½½å®Œæˆ
    // TODO: æ²¡æœ‰æ£€æŸ¥ç°åœ¨æ ‡å¿—ä½æ˜¯å¦é è°±
    {
        std::unique_lock<std::mutex> lock(state.mtx);
        state.loaded = true;
        lock.unlock();
        state.cv_stage.notify_one();
    }

    // Infer Loop
    // è¿›å…¥æ¨ç†å¾ªç¯ï¼ˆè¿™ä¸ªçº¿ç¨‹ä¼šä¸€ç›´è¿è¡Œï¼‰
    while (true) {
        std::unique_lock<std::mutex> lock(state.mtx);
        // å…³é”®ç‚¹ï¼šçº¿ç¨‹åœ¨è¿™é‡Œåœä¸‹æ¥ç­‰å¾…ï¼
        state.cv_stage.wait(lock, [&] { return state.proceed || state.exit_flag; });
        // quit if exit_flag is set
        if (state.exit_flag) {
            break;  // é€€å‡ºçº¿ç¨‹
        }

        // TODO: æ‰§è¡Œæ¨ç†
        // // å ä½ç¬¦ï¼šç®€å•è¿”å›ä¸€ä¸ªtoken
        // if (req.output && req.batch_size > 0) {
        //     req.output[0] = 1;
        // }

        inferDeviceBatchVision(meta, *rsrc, idev, ndev, 
                                req.image_data, req.output);

        // // === LLaVAå››é˜¶æ®µæ¨ç†æµç¨‹ ===
        // // é˜¶æ®µ1: Vision Encoder (å¦‚æœæœ‰å›¾åƒ)
        // if (req.image_data != nullptr) {
        //     state.current_stage = 1;
        //     state.stage_completed = false;
        //     lock.unlock();
        //     state.cv_stage.notify_one(); // é€šçŸ¥ä¸»çº¿ç¨‹è¿›å…¥é˜¶æ®µ1

        //     // TODO: å®ç°vision encoding
        //     // encodeVisionFeatures(meta, *rsrc, req.image_data, state.vision_features);

        //     lock.lock();
        //     state.stage_completed = true;
        //     state.current_stage = 2;
        // }

        // // é˜¶æ®µ2: MultiModal Projector (å¦‚æœæœ‰å›¾åƒç‰¹å¾)
        // if (state.vision_features != nullptr) {
        //     lock.unlock();
        //     state.cv_stage.notify_one(); // é€šçŸ¥ä¸»çº¿ç¨‹è¿›å…¥é˜¶æ®µ2

        //     // TODO: å®ç°multimodal projection
        //     // projectMultiModalFeatures(meta, *rsrc, state.vision_features, state.projected_features);

        //     lock.lock();
        //     state.stage_completed = true;
        //     state.current_stage = 3;
        // }

        // // é˜¶æ®µ3: Language Model Prefill (åŒ…å«KV-Cache)
        // state.current_stage = 3;
        // state.stage_completed = false;
        // lock.unlock();
        // state.cv_stage.notify_one(); // é€šçŸ¥ä¸»çº¿ç¨‹è¿›å…¥é˜¶æ®µ3

        // // TODO: å®ç°language model prefill
        // // è¿™é‡Œè°ƒç”¨Jiugeçš„æ¨ç†é€»è¾‘æ¥å¤„ç†text tokens + projected vision features
        // // inferDeviceBatchLanguage(meta, *rsrc, idev, ndev, req.input_tokens, req.ntok,
        // //                          req.req_lens, req.nreq, req.req_pos, req.kv_caches,
        // //                          req.temperature, req.topk, req.topp, req.output, nullptr);

        // lock.lock();
        // state.stage_completed = true;
        // state.current_stage = 4;

        // // é˜¶æ®µ4: KV-Cache Compression (å¯é€‰)
        // if (req.kv_caches != nullptr && state.stage_completed) {
        //     lock.unlock();
        //     state.cv_stage.notify_one(); // é€šçŸ¥ä¸»çº¿ç¨‹è¿›å…¥é˜¶æ®µ4

        //     // TODO: å®ç°KV-Cacheå‹ç¼© (Future: é›†æˆFastcache)
        //     // compressKVCaches(meta, *rsrc, req.kv_caches);

        //     lock.lock();
        //     state.stage_completed = true;
        // }

        // // ç®€å•å ä½ç¬¦ï¼šè¿”å›ä¸€ä¸ªtoken (ä¸´æ—¶)
        // if (req.output && req.batch_size > 0) {
        //     req.output[0] = 1; // æš‚æ—¶è¿”å›å›ºå®štoken
        // }



        state.proceed = false;  // é‡ç½®ä¿¡å·
        lock.unlock();
        // é€šçŸ¥ä¸»çº¿ç¨‹ï¼šè¿™ä¸ªè®¾å¤‡å®Œæˆäº†æ¨ç†
        state.cv_stage.notify_one();
    }
    // Clean-Up
    releaseDeviceResource(*rsrc);
    setInferenceContext(nullptr); // Clear the context when done
}



// // LLaVAå››é˜¶æ®µç»Ÿä¸€æ¨ç†å®ç°
// void LlavaModel::inferBatchLlava(const uint32_t* input_tokens, const void* image_data,
//                                 void** kv_caches, uint32_t batch_size,
//                                 uint32_t* output) {
//     // 1. è®¾ç½®æ¨ç†è¯·æ±‚å‚æ•°
//     req.input_tokens = input_tokens;
//     req.image_data = image_data;
//     req.kv_caches = kv_caches;
//     req.batch_size = batch_size;
//     req.ntok = batch_size; // ç®€åŒ–ï¼šå‡è®¾æ¯ä¸ªè¯·æ±‚åªæœ‰ä¸€ä¸ªtoken
//     req.nreq = 1; // ç®€åŒ–ï¼šå‡è®¾åªæœ‰ä¸€ä¸ªè¯·æ±‚
//     req.output = output;

//     // 2. å¯åŠ¨æ‰€æœ‰è®¾å¤‡çº¿ç¨‹
//     auto ndev = dev_resources.size();
//     for (size_t i = 0; i < ndev; i++) {
//         std::unique_lock<std::mutex> lock(states[i].mtx);
//         states[i].proceed = true;
//         lock.unlock();
//         states[i].cv_stage.notify_one(); // å‘å‡ºæ¨ç†å¼€å§‹ä¿¡å·
//     }

//     // 3. ç­‰å¾…æ‰€æœ‰è®¾å¤‡å®Œæˆ
//     for (size_t i = 0; i < ndev; i++) {
//         std::unique_lock<std::mutex> lock(states[i].mtx);
//         states[i].cv_stage.wait(lock, [&] { return !(states[i].proceed); });
//         lock.unlock();
//     }

//     // 4. æ¸…ç†è¯·æ±‚å‚æ•°
//     req.input_tokens = nullptr;
//     req.image_data = nullptr;
//     req.kv_caches = nullptr;
//     req.output = nullptr;
// }

// æ¨¡ä»¿jiuge.cppçš„LlavaModel constructor
LlavaModel::LlavaModel(const LlavaMeta *_meta, const LlavaWeights *weights,
                      infiniDevice_t device_, std::vector<int> device_ids) : meta(*_meta) {
    int ndev = int(device_ids.size());
    device = device_;
    dev_ids = device_ids;
    dev_resources = std::vector<LlavaDeviceResource>(ndev);  // æ¯ä¸ªè®¾å¤‡çš„èµ„æº
    states = std::vector<LlavaInferState>(ndev);              // æ¯ä¸ªè®¾å¤‡çš„çŠ¶æ€
    threads.resize(ndev);                                   // æ¯ä¸ªè®¾å¤‡çš„çº¿ç¨‹

    RUN_INFINI(infinirtInit());

    auto comms = std::vector<infinicclComm_t>(ndev, nullptr);
    if (ndev > 1) {
        RUN_INFINI(infinicclCommInitAll(device, comms.data(), ndev, dev_ids.data()));
    }

    // ğŸ§µğŸ§µğŸ§µ è¿™é‡Œåˆ›å»ºçº¿ç¨‹ï¼
    for (int i = 0; i < ndev; i++) {
        threads[i] = std::thread(
            launchLlavaDevice, 
            std::cref(meta), 
            weights, 
            &dev_resources[i], 
            std::ref(states[i]), 
            std::ref(req), 
            device, 
            i, 
            ndev, 
            dev_ids[i], 
            comms[i]);

        // â³ çº¿ç¨‹ç«‹å³å¯åŠ¨ï¼Œè¿›å…¥launchLlavaDeviceå‡½æ•°
        // ğŸ˜´ åœ¨cv_stage.wait()å¤„å¼€å§‹ä¼‘çœ ç­‰å¾…
    }

    // ç­‰å¾…æ‰€æœ‰è®¾å¤‡çº¿ç¨‹åŠ è½½å®Œæˆ - ä½¿ç”¨cv_loadä¸jiuge.cppä¿æŒä¸€è‡´
    for (int i = 0; i < ndev; i++) {
        std::unique_lock<std::mutex> lock(states[i].mtx);
        states[i].cv_stage.wait(lock, [&] { return states[i].loaded; });
        lock.unlock();
    }
}


// // æœ€ç®€å•çš„ç»Ÿä¸€æ¨ç†æ¥å£
// void LlavaModel::inferBatchLlava(const uint32_t* input_tokens, const void* image_data,
//                                void** kv_caches, const char* mode, uint32_t batch_size,
//                                uint32_t* output) {
//     // æš‚æ—¶åªæ˜¯å ä½ç¬¦å®ç°
//     if (output && batch_size > 0) {
//         output[0] = 1;  // è¿”å›ä¸€ä¸ªç®€å•çš„token
//     }
// }

// // å„é˜¶æ®µæ‰§è¡Œå‡½æ•°çš„å ä½ç¬¦å®ç°
// void LlavaModel::executeVisionStage() {
//     // å ä½ç¬¦
// }

// void LlavaModel::executePrefillStage() {
//     // å ä½ç¬¦
// }

// void LlavaModel::executeCompressStage() {
//     // å ä½ç¬¦
// }

// void LlavaModel::executeDecodeStage() {
//     // å ä½ç¬¦
// }

// void LlavaModel::workerLoop() {
//     // å ä½ç¬¦
// }




// API implementations - æ¨¡ä»¿jiuge.cppçš„createJiugeModel
__C struct LlavaModel *createLlavaModel(const LlavaMeta *meta,
                                        const LlavaWeights *weights,
                                        infiniDevice_t device,
                                        int ndev,
                                        const int *dev_ids) {
    std::vector<int> device_ids_vec(ndev);
    std::copy(dev_ids, dev_ids + ndev, device_ids_vec.begin());
    LlavaModel *model = new LlavaModel(meta, weights, device, device_ids_vec);
    return model;
}

__C void destroyLlavaModel(struct LlavaModel *model) {
    if (!model) {
        return;
    }

    auto ndev = model->dev_resources.size();

    // é€šçŸ¥æ‰€æœ‰è®¾å¤‡çº¿ç¨‹é€€å‡º
    for (size_t idev = 0; idev < ndev; idev++) {
        std::unique_lock<std::mutex> lock(model->states[idev].mtx);
        model->states[idev].exit_flag = true;
        lock.unlock();
        model->states[idev].cv_stage.notify_one();
    }

    // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
    for (size_t idev = 0; idev < ndev; idev++) {
        model->threads[idev].join();
    }

    delete model;
}

// C API: æ‰¹é‡è§†è§‰ç¼–ç ï¼ˆç”¨äºPythonæ¥å£ï¼‰
__C void inferBatchLlavaVison(struct LlavaModel *model,
                           const void *image_data,
                           void *output) {
    if (!model || !image_data || !output) {
        return;
    }

    // 1. è®¾ç½®æ¨ç†å‚æ•°ï¼ˆæ¨¡ä»¿inferBatchJiugeï¼‰
    // TODO: æ„Ÿè§‰è¿™é‡Œçš„reqç»“æ„å¯èƒ½è¦é€æ¸æ”¹çš„åƒ struct InferRequest 
    model->req.input_tokens = nullptr;  // vision encodingä¸éœ€è¦input_tokens
    model->req.image_data = image_data;
    model->req.kv_caches = nullptr;     // vision encodingä¸éœ€è¦kv_caches
    model->req.batch_size = 1;          // ç®€åŒ–ï¼šå‡è®¾batch_sizeä¸º1
    model->req.ntok = 0;               // vision encodingä¸éœ€è¦tokens
    model->req.nreq = 1;               // ç®€åŒ–ï¼šå‡è®¾ä¸€ä¸ªè¯·æ±‚
    model->req.output = (uint32_t*)output;  // å°†outputè½¬æ¢ä¸ºuint32_tæŒ‡é’ˆ

    //////////////////////////////////////////////
    auto vision_embed_dim = model->meta.vision_meta.vision_embed_dim;
    auto num_patches = model->meta.vision_meta.num_patches;
    auto total_features = vision_embed_dim * num_patches;
    printf("inferBatchLlavaVison called: image_data=%p, output=%p\n", image_data, output);
    printf("Vision config: embed_dim=%zu, num_patches=%zu, total_features=%zu\n",
           vision_embed_dim, num_patches, total_features);
    //////////////////////////////////////////////


    // 2. é€šçŸ¥æ‰€æœ‰è®¾å¤‡çº¿ç¨‹å¼€å§‹å·¥ä½œï¼ˆæ¨¡ä»¿inferBatchJiugeï¼‰
    // TODO: æ³¨æ„ï¼Œå’Œjiugeä¸ä¸€æ ·çš„åœ°æ–¹åœ¨äºï¼Œæˆ‘ä»¬è¿™é‡Œç°åœ¨åªæœ‰ä¸€ä¸ªä¿¡å·é‡
    for (size_t idev = 0; idev < model->dev_ids.size(); idev++) {
        std::unique_lock<std::mutex> lock(model->states[idev].mtx);
        model->states[idev].proceed = true;  // è®¾ç½®ä¿¡å·
        lock.unlock();
        model->states[idev].cv_stage.notify_one();  // å”¤é†’çº¿ç¨‹ï¼ˆLLaVAä½¿ç”¨cv_stageï¼‰
    }

    // 3. ç­‰å¾…æ‰€æœ‰è®¾å¤‡çº¿ç¨‹å®Œæˆå·¥ä½œï¼ˆæ¨¡ä»¿inferBatchJiugeï¼‰
    for (size_t i = model->dev_ids.size(); i > 0; i--) {
        auto idev = i - 1;
        std::unique_lock<std::mutex> lock(model->states[idev].mtx);
        model->states[idev].cv_stage.wait(lock, [&] { return !(model->states[idev].proceed); });
        lock.unlock();
    }

    printf("inferBatchLlavaVison: vision encoding completed\n");
}

// æš‚æ—¶æ³¨é‡Šæ‰å…¶ä»–å¤æ‚çš„APIå‡½æ•°ï¼Œåªä¿ç•™æœ€åŸºæœ¬çš„