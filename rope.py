import torch
import torch.nn as nn
import math
from typing import Optional

class RotaryPositionEmbeddingSimple(nn.Module):
    """
    ä¿®å¤bugåçš„ç›´è§‚RoPEå®ç°
    """
    
    def __init__(self, dim: int, base: int = 10000):
        super().__init__()
        
        assert dim % 2 == 0, f"ç»´åº¦å¿…é¡»æ˜¯å¶æ•°ï¼Œå½“å‰dim={dim}"
        
        self.dim = dim
        self.base = base
        
        print(f"ğŸ”§ RoPEåˆå§‹åŒ–: dim={dim}, base={base}")
    
    def forward(self, x: torch.Tensor, positions: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        ä¿®å¤bugçš„RoPEå‰å‘ä¼ æ’­
        """
        print(f"\nğŸ”„ å¼€å§‹RoPEè®¡ç®—...")
        print(f"   è¾“å…¥å½¢çŠ¶: {x.shape}")
        
        # ä¿å­˜åŸå§‹å½¢çŠ¶
        original_shape = x.shape
        
        # è·å–è¾“å…¥ä¿¡æ¯
        if x.dim() == 3:  # [batch, seq_len, dim]
            batch_size, seq_len, dim = x.shape
            num_heads = 1
        elif x.dim() == 4:  # [batch, heads, seq_len, dim]
            batch_size, num_heads, seq_len, dim = x.shape
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç»´åº¦: {x.dim()}")
        
        # å¤„ç†ä½ç½®ç¼–ç 
        if positions is None:
            positions = torch.arange(seq_len, device=x.device)
            print(f"   è‡ªåŠ¨ç”Ÿæˆä½ç½®: {positions.tolist()}")
        else:
            print(f"   ä½¿ç”¨è‡ªå®šä¹‰ä½ç½®: {positions.tolist()}")
        
        # 1. è®¡ç®—é¢‘ç‡å‘é‡
        print(f"\nğŸ“Š æ­¥éª¤1: è®¡ç®—é¢‘ç‡å‘é‡")
        indices = torch.arange(0, dim, 2).float().to(x.device)  # [0, 2, 4, ..., dim-2]
        inv_freq = 1.0 / (self.base ** (indices / dim))
        print(f"   é¢‘ç‡å‘é‡: {inv_freq.tolist()}")
        
        # 2. è®¡ç®—è§’åº¦çŸ©é˜µ
        print(f"\nğŸ“Š æ­¥éª¤2: è®¡ç®—è§’åº¦çŸ©é˜µ")
        # positions: [seq_len] -> [seq_len, 1]
        # inv_freq: [dim/2] -> [1, dim/2]
        positions_expanded = positions.unsqueeze(-1)  # [seq_len, 1]
        inv_freq_expanded = inv_freq.unsqueeze(0)    # [1, dim/2]
        
        angles = positions_expanded * inv_freq_expanded  # [seq_len, dim/2]
        print(f"   è§’åº¦çŸ©é˜µå½¢çŠ¶: {angles.shape}")
        
        # 3. æ‰©å±•è§’åº¦åˆ°æ¯ä¸ªç»´åº¦
        angles_expanded = angles.repeat_interleave(2, dim=-1)  # [seq_len, dim]
        print(f"   æ‰©å±•åè§’åº¦å½¢çŠ¶: {angles_expanded.shape}")
        
        # 4. è®¡ç®—æ­£å¼¦ä½™å¼¦
        sin = torch.sin(angles_expanded)  # [seq_len, dim]
        cos = torch.cos(angles_expanded)  # [seq_len, dim]
        print(f"   æ­£å¼¦å½¢çŠ¶: {sin.shape}, ä½™å¼¦å½¢çŠ¶: {cos.shape}")
        
        # 5. å…³é”®ä¿®å¤ï¼šæ­£ç¡®è°ƒæ•´å½¢çŠ¶ä»¥åŒ¹é…è¾“å…¥
        print(f"\nğŸ“Š æ­¥éª¤3: è°ƒæ•´å½¢çŠ¶åŒ¹é…è¾“å…¥")
        if x.dim() == 3:  # [batch, seq_len, dim]
            # æ‰©å±•ç»´åº¦: [seq_len, dim] -> [batch, seq_len, dim]
            sin = sin.unsqueeze(0).expand(batch_size, -1, -1)  # ä½¿ç”¨expandè€Œä¸æ˜¯repeat
            cos = cos.unsqueeze(0).expand(batch_size, -1, -1)
        elif x.dim() == 4:  # [batch, heads, seq_len, dim]
            # æ‰©å±•ç»´åº¦: [seq_len, dim] -> [batch, heads, seq_len, dim]
            sin = sin.unsqueeze(0).unsqueeze(0).expand(batch_size, num_heads, -1, -1)
            cos = cos.unsqueeze(0).unsqueeze(0).expand(batch_size, num_heads, -1, -1)
        
        print(f"   è°ƒæ•´åæ­£å¼¦å½¢çŠ¶: {sin.shape}")
        print(f"   è°ƒæ•´åä½™å¼¦å½¢çŠ¶: {cos.shape}")
        print(f"   è¾“å…¥xå½¢çŠ¶: {x.shape}")
        
        # 6. åº”ç”¨æ—‹è½¬
        result = self._apply_rotation_detailed(x, sin, cos)
        
        print(f"âœ… RoPEè®¡ç®—å®Œæˆ")
        print(f"   è¾“å…¥: {original_shape} -> è¾“å‡º: {result.shape}")
        
        return result
    
    def _apply_rotation_detailed(self, x: torch.Tensor, sin: torch.Tensor, cos: torch.Tensor) -> torch.Tensor:
        """ä¿®å¤åçš„æ—‹è½¬æ“ä½œ"""
        print(f"\nğŸ“Š æ­¥éª¤4: åº”ç”¨æ—‹è½¬æ“ä½œ")
        
        # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦åŒ¹é…
        assert x.shape == sin.shape == cos.shape, f"å½¢çŠ¶ä¸åŒ¹é…: x{x.shape}, sin{sin.shape}, cos{cos.shape}"
        
        # åˆ†å‰²è¾“å…¥å¼ é‡
        x1 = x[..., 0::2]  # æ‰€æœ‰å¶æ•°ç´¢å¼•ç»´åº¦
        x2 = x[..., 1::2]  # æ‰€æœ‰å¥‡æ•°ç´¢å¼•ç»´åº¦
        
        print(f"   x1å½¢çŠ¶ (å¶æ•°ç»´åº¦): {x1.shape}")
        print(f"   x2å½¢çŠ¶ (å¥‡æ•°ç»´åº¦): {x2.shape}")
        
        # åˆ†å‰²æ­£å¼¦ä½™å¼¦ï¼ˆç¡®ä¿å½¢çŠ¶åŒ¹é…ï¼‰
        sin1 = sin[..., 0::2]  # å¯¹åº”x1çš„æ­£å¼¦
        cos1 = cos[..., 0::2]  # å¯¹åº”x1çš„ä½™å¼¦
        sin2 = sin[..., 1::2]  # å¯¹åº”x2çš„æ­£å¼¦  
        cos2 = cos[..., 1::2]  # å¯¹åº”x2çš„ä½™å¼¦
        
        print(f"   sin1å½¢çŠ¶: {sin1.shape}, cos1å½¢çŠ¶: {cos1.shape}")
        print(f"   sin2å½¢çŠ¶: {sin2.shape}, cos2å½¢çŠ¶: {cos2.shape}")
        
        # åº”ç”¨æ—‹è½¬å…¬å¼ï¼ˆç¡®ä¿å¹¿æ’­æ­£ç¡®ï¼‰
        rotated_x1 = x1 * cos1 - x2 * sin2
        rotated_x2 = x1 * sin1 + x2 * cos2
        
        print(f"   rotated_x1å½¢çŠ¶: {rotated_x1.shape}")
        print(f"   rotated_x2å½¢çŠ¶: {rotated_x2.shape}")
        
        # é‡æ–°ç»„åˆ
        result = torch.stack([rotated_x1, rotated_x2], dim=-1)
        result = result.flatten(start_dim=-2)
        
        print(f"   æœ€ç»ˆè¾“å‡ºå½¢çŠ¶: {result.shape}")
        return result


def test_fixed_version():
    """æµ‹è¯•ä¿®å¤åçš„ç‰ˆæœ¬"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•ä¿®å¤åçš„ç‰ˆæœ¬")
    print("=" * 60)
    
    # æµ‹è¯•1: 3Dè¾“å…¥
    print("æµ‹è¯•1: 3Dè¾“å…¥ [batch, seq_len, dim]")
    dim = 6
    rope = RotaryPositionEmbeddingSimple(dim)
    
    x_3d = torch.randn(2, 3, dim)  # [batch=2, seq_len=3, dim=6]
    positions = torch.tensor([0, 1, 2])
    
    try:
        result_3d = rope(x_3d, positions)
        print("âœ… 3Dè¾“å…¥æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ 3Dè¾“å…¥æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•2: 4Dè¾“å…¥
    print("\næµ‹è¯•2: 4Dè¾“å…¥ [batch, heads, seq_len, dim]")
    x_4d = torch.randn(2, 4, 3, dim)  # [batch=2, heads=4, seq_len=3, dim=6]
    
    try:
        result_4d = rope(x_4d, positions)
        print("âœ… 4Dè¾“å…¥æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ 4Dè¾“å…¥æµ‹è¯•å¤±è´¥: {e}")


def debug_shape_issue():
    """è°ƒè¯•åŸå§‹çš„å½¢çŠ¶é—®é¢˜"""
    print("\n" + "=" * 60)
    print("ğŸ› è°ƒè¯•åŸå§‹çš„å½¢çŠ¶é—®é¢˜")
    print("=" * 60)
    
    dim = 4
    batch_size, seq_len = 2, 3
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    x = torch.randn(batch_size, seq_len, dim)
    positions = torch.arange(seq_len)
    
    print("åŸå§‹é—®é¢˜åˆ†æ:")
    print(f"è¾“å…¥xå½¢çŠ¶: {x.shape}")  # [2, 3, 4]
    
    # è®¡ç®—æ­£å¼¦ä½™å¼¦ï¼ˆé”™è¯¯çš„æ–¹å¼ï¼‰
    indices = torch.arange(0, dim, 2).float()
    inv_freq = 1.0 / (10000 ** (indices / dim))
    
    angles = positions.unsqueeze(-1) * inv_freq.unsqueeze(0)  # [3, 2]
    angles_expanded = angles.repeat_interleave(2, dim=-1)     # [3, 4]
    
    sin = torch.sin(angles_expanded)  # [3, 4]
    cos = torch.cos(angles_expanded)  # [3, 4]
    
    print(f"è®¡ç®—å‡ºçš„sinå½¢çŠ¶: {sin.shape}")  # [3, 4]
    print(f"è®¡ç®—å‡ºçš„coså½¢çŠ¶: {cos.shape}")  # [3, 4]
    
    # é”™è¯¯ï¼šç›´æ¥ä½¿ç”¨ä¼šå¯¼è‡´å½¢çŠ¶ä¸åŒ¹é…
    print(f"âŒ é—®é¢˜: sin{sin.shape} ä¸ x{x.shape} å½¢çŠ¶ä¸åŒ¹é…")
    print(f"âŒ éœ€è¦å°†sinä»[3,4]æ‰©å±•åˆ°[2,3,4]")
    
    # æ­£ç¡®çš„æ–¹å¼
    sin_correct = sin.unsqueeze(0).expand(batch_size, -1, -1)  # [2, 3, 4]
    print(f"âœ… æ­£ç¡®æ‰©å±•å: {sin_correct.shape}")


def simple_demo():
    """ç®€å•çš„æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ğŸ¯ ç®€å•æ¼”ç¤º")
    print("=" * 60)
    
    # ä½¿ç”¨æ›´å°çš„ç»´åº¦ä¾¿äºè§‚å¯Ÿ
    dim = 4
    rope = RotaryPositionEmbeddingSimple(dim, base=100)
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    x = torch.tensor([
        [[1.0, 0.0, 0.5, 0.5],  # ç¬¬ä¸€ä¸ªåºåˆ—
         [0.0, 1.0, 0.3, 0.7]],
        
        [[0.5, 0.5, 1.0, 0.0],  # ç¬¬äºŒä¸ªåºåˆ—  
         [0.7, 0.3, 0.0, 1.0]]
    ])  # [batch=2, seq_len=2, dim=4]
    
    print("è¾“å…¥æ•°æ®:")
    print(f"æ‰¹æ¬¡0, token0: {x[0,0].tolist()}")
    print(f"æ‰¹æ¬¡0, token1: {x[0,1].tolist()}")
    print(f"æ‰¹æ¬¡1, token0: {x[1,0].tolist()}")
    
    # åº”ç”¨RoPE
    result = rope(x)
    
    print("\næ—‹è½¬åæ•°æ®:")
    print(f"æ‰¹æ¬¡0, token0: {result[0,0].tolist()}")
    print(f"æ‰¹æ¬¡0, token1: {result[0,1].tolist()}")
    print(f"æ‰¹æ¬¡1, token0: {result[1,0].tolist()}")


def verify_calculation():
    """éªŒè¯è®¡ç®—æ­£ç¡®æ€§"""
    print("\n" + "=" * 60)
    print("âœ… éªŒè¯è®¡ç®—æ­£ç¡®æ€§")
    print("=" * 60)
    
    # ä½¿ç”¨2ç»´å‘é‡æ‰‹åŠ¨éªŒè¯
    dim = 2
    rope = RotaryPositionEmbeddingSimple(dim, base=10000)
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•å‘é‡
    x = torch.tensor([[[1.0, 0.0]]])  # [1, 1, 2]
    positions = torch.tensor([1])
    
    # æ‰‹åŠ¨è®¡ç®—æœŸæœ›ç»“æœ
    # å¯¹äº2ç»´å‘é‡ï¼Œåªæœ‰ä¸€ä¸ªé¢‘ç‡Î¸
    theta = 1.0 / (10000 ** (0 / 2))  # i=0, Î¸=1.0
    angle = 1 * theta  # ä½ç½®1ï¼Œè§’åº¦=1å¼§åº¦
    
    # æ‰‹åŠ¨æ—‹è½¬è®¡ç®—
    x_manual = torch.tensor([
        [1.0 * math.cos(angle) - 0.0 * math.sin(angle),
         1.0 * math.sin(angle) + 0.0 * math.cos(angle)]
    ])
    
    # RoPEè®¡ç®—
    x_rope = rope(x, positions)
    
    print(f"æ‰‹åŠ¨è®¡ç®—: {x_manual.tolist()}")
    print(f"RoPEè®¡ç®—: {x_rope[0,0].tolist()}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸€è‡´
    diff = torch.abs(x_manual - x_rope[0,0]).max().item()
    if diff < 1e-6:
        print("âœ… è®¡ç®—æ­£ç¡®æ€§éªŒè¯é€šè¿‡")
    else:
        print(f"âŒ è®¡ç®—æœ‰å·®å¼‚: {diff}")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ä¿®å¤åçš„RoPEæµ‹è¯•")
    
    # è¿è¡Œæµ‹è¯•
    test_fixed_version()
    debug_shape_issue()
    simple_demo()
    verify_calculation()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    torch.manual_seed(42)
    main()